---
title: "Create Configuration Manifests"
---

import Tabs from '@theme/Tabs';
import TabItem from '@theme/TabItem';

## Creating IPI Installation Config File 

In this section we will create our installation configuration files which will be then used in the next section to deploy an OCP cluster.

### Preparing Provisioning VM

We will use your UserXX-LinuxToolsVM as a provisioning VM to deploy OCP.

1. Logon to your UserXX-LinuxToolsVM 

2. Copy the Root CA's public certificate to the local certiface repository

   ```bash
   cd /root/xyz
   cp rootCA.crt /etc/pki/ca-trust/source/anchors/
   ```
3. Update the local CA trust repository with the new one your created

   ```bash
   update-ca-trust
   ```
   Now your UserXX-LinuxToolsVM will be able to trust SSL connections to Prism Central and will ``openshift-install`` binary

4. Create a local ssh key which we will then use to access all the OCP cluster nodes/vms
   
   ```bash
   ssh-keygen
   ```
   ```buttonless title="Execution example - accept default values and no passphrase"
   Generating public/private rsa key pair.
   Enter file in which to save the key (/root/.ssh/id_rsa): 
   /root/.ssh/id_rsa already exists.
   Overwrite (y/n)? y
   Enter passphrase (empty for no passphrase):  
   Enter same passphrase again: 
   Your identification has been saved in /root/.ssh/id_rsa.
   Your public key has been saved in /root/.ssh/id_rsa.pub.
   The key fingerprint is:
   SHA256:1gjz5zWw+aS7hiEje/pDGY2N5Y5anh6JEQYVf9GRmgs root@centos
   The key's randomart image is:
   +---[RSA 2048]----+
   |  ..o.  ...o     |
   |   . .  ..o      |
   |    o +B.o.      |
   |   . .E=*o +     |
   |    .  *S.= +    |
   |    .oBo+o = .   |
   |    .Bo+ oo .    |
   |    o =.. ..     |
   |    .=o. .o.     |
   +----[SHA256]-----+
   ```
### Creating the Installation Manifests (files)

1. In your UserXX-LinuxToolsVM 

2. Change to you working directory that we created before (if not there already)

   ```bash
   cd /root/xyz
   ```
3. Run the create install config command

   :::tip 
   Copy the pull_secret value from Red Hat Console or the ``pull_secret.json`` file into your clipboard as you will need to input in the interactive command execution
   :::

   ```bash
   openshift-install create install-config 
   ```
   ```buttonless title="Execution example - use up and down arrow keys to choose options"
   # openshift-install create install-config 
   ? SSH Public Key /root/.ssh/id_rsa.pub
   ? Platform nutanix
   ? Prism Central pc.ntnxlab.local                   # << Your Prism Central FQDN address
   ? Port 9440
   ? Username admin
   ? Password [? for help] **********                 # << Your Prism Central password entered as plain text
   INFO Connecting to Prism Central pc.ntnxlab.local 
   ? Prism Element PHX-SPOC018-4                      # << Choose your Prism Element cluster
   INFO Defaulting to only available network: Primary 
   ? Virtual IP Address for API 10.38.18.219          # << Type the API IP 
   ? Virtual IP Address for Ingress 10.38.18.220      # << Type the Ingress IP
   ? Base Domain ntnxlab.local                        # << Type the name of your base domain 
   ? Cluster Name xyz                                 # << Type the name of your sub domain or OCP cluster's name
   ? Pull Secret [? for help] ************************************************
   INFO Install-Config created in: .
   ```

4. Now we have to prepare the install-config.yaml file by adding the following details:

   - Your self hosted Root CA's certificate
   - Number of replcas for worker nodes (3 workers to 2 worker)
   - Machine network details (your HPOC's subnet)
   

5. Add the details:

    ```bash
    vim install-config.yaml
    # if vim is not present, install using #yum install -y vim
    ```
 
    ```mdx-code-block
    <BrowserWindow>
    <details>
    <summary>Toggle me for a file editing tip</summary>
    <div>
    <body>
 
    :::tip Editing instructions
    - Inside vim, move the cursor the to beigging on the line ``-----BEGIN CERTIFICATE-----``
    - Use ``crtl`` + ``v`` keyboard combination to enter visual block mode 
    - Select the lines until ``-----END CERTIFICATE-----``
    - Press ``I`` (capital I using Shift key)
    - Type in two spaces
    - Press ``esc`` key
    - Type ``wq!``
    :::
 
    </body>
    </div>
    </details>
    </BrowserWindow>
    ```
    ```yml {4-13,19,35} title="Sample install-config.yaml file - Edit the highlighted parts"
    apiVersion: v1
    baseDomain: ntnxlab.local
    additionalTrustBundle: | 
        -----BEGIN CERTIFICATE-----                                        ## << contents of rootCA.crt 
        MIIEBTCCAu2gAwIBAgIJAPDfr9SQbStmMA0GCSqGSIb3DQEBCwUAMIGYMQswCQYD
        VQQGEwJKUDEOMAwGA1UECAwFQ2hpYmExEDAOBgNVBAcMB0thc2hpd2ExEDAOBgNV
        BAoMB251dGFuaXgxDzANBgNVBAsMBnJvb3RjYTEdMBsGA1UEAwwUcm9vdGNhLm50
        <snipped for brevity> 
        WtAYCgGyXEUNVltpXBg8M/0S3WLgkW+Z0r408vC4kIIHAWANfJiGt3qLYeVep91h
        NDB2Cn14G9CSCN3Pb1jO2wz9sc1E3rEPo1VHjyOjWccDayTJ3i/lNz6taPbXcmV7
        3ZIeb1v6oRYfB4O/XQMvonTHwTXgumBWOxGcoh5g4h9av+v4oPykJqJexNSbwtQy
        m11nydu44BpIGL+LOm5z0jMd2JrSJFI2Fg==
        -----END CERTIFICATE-----
    compute:
    - architecture: amd64
      hyperthreading: Enabled
      name: worker
      platform: {}
      replicas: 3 ## << This can be just 2 nodes
    controlPlane:
      architecture: amd64
      hyperthreading: Enabled
      name: master
      platform: {}
      replicas: 3
    credentialsMode: Manual
    metadata:
      creationTimestamp: null
      name: xyz
    networking:
      clusterNetwork:
      - cidr: 10.128.0.0/14
        hostPrefix: 23
      machineNetwork:
      - cidr: 10.38.18.192/26   ## << This should be your HPOC cluster's subnet
      networkType: OpenShiftSDN
      serviceNetwork:
      - 172.30.0.0/16
    platform:
    nutanix:
       apiVIP: 10.38.18.219
       ingressVIP: 10.38.18.220
       prismCentral:
          endpoint:
            address: pc.ntnxlab.local
            port: 9440
          password: techX2020!
          username: admin
       prismElements:
       - endpoint:
           address: 10.38.18.199
           port: 9440
         uuid: 0005e93a-3b29-fa1a-6b84-ac1f6b6922d1
       subnetUUIDs:
       - 34c84ddf-6c6e-46bf-9a5c-617b0b08a92c
    publish: External
    pullSecret: '{"auths": ...}'
    sshKey: |
      ssh-rsa AAAA..
    ```

6. Now we can create all the other manifests required for OCP cluster installation
   
   ```bash
   openshift-install create manifests
   ```
   ```buttonless title="Output"
   openshift-install create manifests
   INFO Consuming Install Config from target directory 
   INFO Manifests created in: manifests and openshift
   ```

7. Since we will be using CSI provisioned with Nutanix HCI storage later in the lab, we need to **enable iSCSI daemon** on all the worker nodes (optional for Master nodes) using [Machine Configuration Operator](https://docs.openshift.com/container-platform/4.10/post_installation_configuration/machine-configuration-tasks.html#machine-config-operator_post-install-machine-configuration-tasks) (MCO).
   
   :::caution 
   iSCSI daemon is usually in a disabled state while deploying OCP clusters. It is up to the customers to decide when and where to enable these daemons. 

   In our lab, we have decided to enable it now, so we can use Nutanix CSI to provide storage to applications. 
   
   Enabling iSCSI daemon at this stage prevents any reboot requirements after the cluster is deployed and serving workloads. 
   :::

   ```bash title="Create MCO config to start iSCSI daemon for worker nodes"
   cat << EOF > manifests/99-worker-custom-enable-iscsid.yaml
   apiVersion: machineconfiguration.openshift.io/v1
   kind: MachineConfig
   metadata:
     labels:
       machineconfiguration.openshift.io/role: worker
     name: 99-worker-custom-enable-iscsid
   spec:
     config:
       ignition:
         version: 3.1.0
       systemd:
         units:
         - enabled: true
           name: iscsid.service
   EOF
   ```
   The following step is optional. Customer wouldn't usually run workloads on master nodes. But the following would be the way to prepare master nodes to access PV/PVC for their workloads.

   ```bash title="Optional - create MCO config to start iSCSI daemon for master nodes"
   cat << EOF > manifests/99-master-custom-enable-iscsid.yaml
   apiVersion: machineconfiguration.openshift.io/v1
   kind: MachineConfig
   metadata:
     labels:
       machineconfiguration.openshift.io/role: master
     name: 99-master-custom-enable-iscsid
   spec:
     config:
       ignition:
         version: 3.1.0
       systemd:
         units:
         - enabled: true
           name: iscsid.service
   EOF
   ```


7. Check the contents of ``manifests`` and ``openshift`` directories to make sure all the files are present (including iSCSI daemon MCO config. files)

   ```bash
   ls -l openshift manifests
   ```
8. We have one last requirement; to let IPI installer know that we will be using a self generated CA bundle. 
   
   Edit the ``manifests/cluster-proxy-01-config.yaml`` file to do this.

   ```bash
   vi manifests/cluster-proxy-01-config.yaml
   ```

9. Let the IPI installer know that we will be using a user generated Certificate Authority (CA) for this installation. 

   ```yml {8} title="Add the user-ca-bundle as trusted CA"
   apiVersion: config.openshift.io/v1
   kind: Proxy
   metadata:
     creationTimestamp: null
     name: cluster
   spec:
     trustedCA:
       name: "user-ca-bundle" 
   status: {}
   ```

   :::note
   
   The ``user-ca-bundle`` configuration in ``manifests/cluster-proxy-01-config.yaml`` is not required when you or your customer is using a public CA.

   :::

   We will now move on to the IPI deployment part.